from transformers import pipeline
import torch
import pandas as pd

with open('./token.txt', 'r') as f:
    TOKEN = f.read()

pipe = pipeline("text-generation", model="mistralai/Mistral-7B-Instruct-v0.2", device_map="cuda",
                model_kwargs={"load_in_4bit": True,
                              "bnb_4bit_compute_dtype": torch.bfloat16},
                torch_dtype=torch.float16, token=TOKEN)

list_group = [
    "Группа: Приветствия. Описание группы: Сообщения, адресованные другим участникам, для начала общения.",
    "Группа: Вопросы о профессиях. Описание группы: Вопросы, связанные с профессиями участников.",
    "Группа: Вопросы о группах. Описание группы: Вопросы, касающиеся организации и функционирования группы.",
    "Группа: Вопросы о ходе обучения. Описание группы: Вопросы, связанные с процессом обучения.",
    "Группа: Недопонимание. Описание группы: Сообщения, содержащие недопонимание или ошибки.",
    "Группа: Понимание. Описание группы: Сообщения, подтверждающие понимание темы обучения.",
    "Группа: Мнение о мероприятии. Описание группы: Сообщения, выражающие мнение участников о мероприятии.",
    "Группа: Опыт. Описание группы: Сообщения, описывающие опыт участников.",
    "Группа: Технические вопросы. Описание группы: Вопросы, связанные с технической стороной обучения.",
    "Группа: Технические проблемы. Описание группы: Сообщения, касающиеся технических проблем.",
    "Группа: Обсуждение кода. Описание группы: Обсуждения кода, связанные с обучением.",
    "Группа: Нформальные нейтральные сообщения. Описание группы: Безформальные, нейтральные сообщения.",
    "Группа: Позитивные неформальные сообщения. Описание группы: Позитивные, неформальные сообщения.",
    "Группа: Комплименты. Описание группы: Комплименты, адресованные другим участникам.",
    "Группа: Флуд. Описание группы: Сообщения, не связанные с темой обучения.",
    "Группа: Токсичные сообщения. Описание группы: Сообщения, содержащие негативность и враждебность.",
    "Группа: Политика. Описание группы: Сообщения, связанные с политикой.",
    "Группа: Полезные ссылки. Описание группы: Ссылки, предоставляющие полезную информацию.",
    "Группа: Фишинговые ссылки. Описание группы: Ссылки, предназначенные для манипулирования.",
    "Группа: Прощания. Описание группы: Сообщения, предназначенные для завершения общения.",
]

text_group = ''
for num, group in enumerate(list_group):
    text_group = text_group + f"{num+1}. {group}\n"


def predict(analysis: str):

    text = '''Russian language. Я превосходный русскоязычный лингвист-аналитик. Я разбираю текст, содержащий аналитическую информацию по комментариям на онлайн уроке.
            Цель моей работы - автоматическое составление аналитического отчета по проведенному уроку.
    Мне передаются ранее определенные группы семантики комментариев. Это необходимо для понимания семантики комментариев.
    Успешные уроки содержат положительные комментарии, ученики отвечают на вопросы, происходит взаимодейтсвие с учителем, положительная оценка урока. 
    Не усепшные уроки содержат комментарии, с обсуждениями не по теме, нет обратной связи и вопросов, нет активности.
    [INST]Задача состоит в том, чтобы составить аналитический отчет по проведенному уроку на основе собранной аналитике по уроку и комментрием к нему.
    Определены следующие семантические группы комментариев:''' + text_group + '''
        №. Новая группа ...
        
        Аналитическое сообщение по уроку: ''' + analysis + '''
        Ответ должен содержать достаточно информации для оценки качества проведенного урока. Информация должна быть связяна и логична.
        Вывести эту важную информацию по пунктам: оценка позитивного восприятия, ругань, технические неполадки, уровень
    сложности уроков, поведение участников онлайн урока. 
        Расчитать статистику по комментариям и времени урока.
        В результате в конце ответа должна быть представлена субъективная оценка качества урока. Необходимо добавить рекомендации по улучшению урока.
    Ответ в формате отчета.[/INST]
    Ответ: '''
    return pipe(text, max_length=1024*4,
                pad_token_id=pipe.tokenizer.eos_token_id, temperature=0.6, do_sample=False)[0]['generated_text']
